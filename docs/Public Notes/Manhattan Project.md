The history of the nuclear bomb begins in the early 20th century, when scientists began to study the properties of atoms and the potential for releasing large amounts of energy through nuclear reactions.

In 1938, German chemists Otto Hahn and Fritz Strassmann discovered the process of nuclear fission, in which the nucleus of an atom is split into two smaller nuclei, releasing a large amount of energy in the process.

This discovery led to a race among several countries to develop a nuclear weapon during World War II. The United States, under the Manhattan Project, developed the first atomic bomb, which was successfully tested in New Mexico on July 16, 1945.

On August 6, 1945, the United States dropped an atomic bomb on the Japanese city of Hiroshima, killing an estimated 140,000 people instantly or in the following months due to radiation exposure. Three days later, the United States dropped a second atomic bomb on the city of Nagasaki, killing an estimated 74,000 people.

The use of the atomic bombs on Hiroshima and Nagasaki remains controversial to this day, with some arguing that it was necessary to end the war quickly and others criticizing it as a war crime that caused immense suffering for civilians.

After World War II, several countries developed their own nuclear weapons, leading to a period of nuclear proliferation and a heightened risk of nuclear war. The development of nuclear weapons has also had significant implications for international relations and global politics, including the arms race between the United States and the Soviet Union during the Cold War and ongoing efforts to prevent the spread of nuclear weapons to other countries.

[[How did the Cold War contribute to the computer]] 